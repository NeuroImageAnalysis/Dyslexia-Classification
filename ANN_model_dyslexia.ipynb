{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2903f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import manipulating files libraries\n",
    "import os, glob\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   #if like me you do not have a lot of memory in your GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" #then these two lines force keras to use your CPU\n",
    "# Import graph/image plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# Import loading and manipulating neuroimaging data library\n",
    "import nibabel as nib\n",
    "\n",
    "# Import array manipulating libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import deep learning model libraries\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "# Import date/time library to save models with date/time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c892069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data path\n",
    "data_path = 'final data/*.nii.gz'\n",
    "# Find all files within the location that matches our search string\n",
    "files = glob.glob(data_path)\n",
    "\n",
    "# Get the labels for our data from our csv file\n",
    "Labels = pd.read_csv('labels.csv')\n",
    "# Define our target from the column \"Labels\" as our y in our model\n",
    "target = Labels['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe759242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "(120, 64, 64, 34)\n"
     ]
    }
   ],
   "source": [
    "# Loop through files and load all data files\n",
    "data_all, images = [], []\n",
    "for data_file in sorted(files):\n",
    "    data = nib.load(data_file).get_fdata()\n",
    "    first_vol = data[:,:,:,0]\n",
    "    first = first_vol / 255\n",
    "    data_all.append(first)\n",
    "    \n",
    "# Convert our list into a numpy array\n",
    "images = np.asarray(data_all)\n",
    "\n",
    "print(len(data_all))\n",
    "print (np.shape(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2115f42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]\n",
      "  [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      " [[0.03921569 0.04705882 0.05098039 ... 0.03529412 0.04313725 0.03137255]\n",
      "  [0.03921569 0.03529412 0.05098039 ... 0.04313725 0.03529412 0.04313725]\n",
      "  [0.04705882 0.05098039 0.04313725 ... 0.05098039 0.03529412 0.04313725]\n",
      "  ...\n",
      "  [0.0745098  0.09411765 0.10196078 ... 0.05882353 0.05098039 0.05882353]\n",
      "  [0.08235294 0.06666667 0.09411765 ... 0.05098039 0.05098039 0.05490196]\n",
      "  [0.07058824 0.0745098  0.09019608 ... 0.05490196 0.05490196 0.05882353]]\n",
      "\n",
      " [[0.03921569 0.05098039 0.06666667 ... 0.05098039 0.03921569 0.03921569]\n",
      "  [0.04705882 0.05490196 0.05882353 ... 0.05098039 0.04705882 0.04313725]\n",
      "  [0.04705882 0.05098039 0.05098039 ... 0.04313725 0.04313725 0.04313725]\n",
      "  ...\n",
      "  [0.08627451 0.07058824 0.08627451 ... 0.05490196 0.06666667 0.05098039]\n",
      "  [0.07843137 0.09411765 0.07843137 ... 0.05882353 0.05098039 0.05882353]\n",
      "  [0.06666667 0.07058824 0.09019608 ... 0.05882353 0.05882353 0.05490196]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.05098039 0.05490196 0.05490196 ... 0.02745098 0.03529412 0.03921569]\n",
      "  [0.04705882 0.05490196 0.04705882 ... 0.03137255 0.03137255 0.03137255]\n",
      "  [0.05490196 0.05882353 0.05490196 ... 0.03137255 0.03137255 0.01960784]\n",
      "  ...\n",
      "  [0.09411765 0.07843137 0.09411765 ... 0.05490196 0.0627451  0.05882353]\n",
      "  [0.08627451 0.0627451  0.09411765 ... 0.0627451  0.05882353 0.05490196]\n",
      "  [0.07058824 0.0745098  0.08235294 ... 0.0627451  0.05098039 0.0627451 ]]\n",
      "\n",
      " [[0.04705882 0.03921569 0.04313725 ... 0.03137255 0.03137255 0.03137255]\n",
      "  [0.05098039 0.05098039 0.04705882 ... 0.02352941 0.03137255 0.02745098]\n",
      "  [0.05098039 0.05098039 0.05882353 ... 0.03529412 0.03529412 0.02745098]\n",
      "  ...\n",
      "  [0.07843137 0.07843137 0.08627451 ... 0.04705882 0.05882353 0.05882353]\n",
      "  [0.07843137 0.09803922 0.08235294 ... 0.0627451  0.0627451  0.05490196]\n",
      "  [0.08627451 0.07058824 0.09803922 ... 0.0627451  0.05490196 0.0627451 ]]\n",
      "\n",
      " [[0.04705882 0.04705882 0.04313725 ... 0.03529412 0.02745098 0.03137255]\n",
      "  [0.05098039 0.04705882 0.05490196 ... 0.03529412 0.03137255 0.02352941]\n",
      "  [0.05882353 0.05098039 0.05490196 ... 0.03529412 0.02745098 0.03137255]\n",
      "  ...\n",
      "  [0.08235294 0.07058824 0.09803922 ... 0.06666667 0.07058824 0.05490196]\n",
      "  [0.07843137 0.08627451 0.0745098  ... 0.05882353 0.05882353 0.05490196]\n",
      "  [0.08235294 0.07843137 0.07058824 ... 0.05882353 0.05098039 0.05882353]]]\n"
     ]
    }
   ],
   "source": [
    "print(images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f637a95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "115    1\n",
       "116    1\n",
       "117    1\n",
       "118    1\n",
       "119    1\n",
       "Name: group, Length: 120, dtype: int64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fca8967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 64, 64, 34) (18, 64, 64, 34) (18, 64, 64, 34)\n"
     ]
    }
   ],
   "source": [
    "# Create list of indices\n",
    "N = images.shape[0]\n",
    "indexes = np.arange(N)\n",
    "\n",
    "# Divide our dataset into dyslexics and controls to have a balanced train, validation and test sets\n",
    "dis = indexes[:60]\n",
    "con = indexes[60:]\n",
    "\n",
    "#  Cut the dataset at 80% to create the training, 10% validation and 10% test set\n",
    "size = dis.shape[0]\n",
    "split_1 = int(0.7 * size)\n",
    "split_2 = int(0.85 * size)\n",
    "\n",
    "# Shuffle our dyslexics and controls arrays to create random indexes\n",
    "np.random.shuffle(np.asarray(dis))\n",
    "np.random.shuffle(np.asarray(con))\n",
    "\n",
    "# Create our indexes for our train, validation and test sets according to our previous division (80%, 10%, 10%)\n",
    "indexes_train_dis, indexes_train_con = dis[:split_1], con[:split_1]\n",
    "indexes_val_dis, indexes_val_con   = dis[split_1:split_2], con[split_1:split_2]\n",
    "indexes_test_dis, indexes_test_con = dis[split_2:], con[split_2:]\n",
    "\n",
    "# We concatenate our training, validation and test indexes for dyslexics and controls\n",
    "# By doing that we ensure that each set is balanced with the same number of dyslexics and controls\n",
    "indexes_train = np.concatenate((indexes_train_dis, indexes_train_con), axis=None)\n",
    "indexes_val = np.concatenate((indexes_val_dis, indexes_val_con), axis=None)\n",
    "indexes_test = np.concatenate((indexes_test_dis, indexes_test_con), axis=None)\n",
    "\n",
    "\n",
    "# Split the data into training, validation and test sets according to the indexes created previously\n",
    "X_train = images[indexes_train, ...]\n",
    "X_val = images[indexes_val, ...]\n",
    "X_test = images[indexes_test, ...]\n",
    "print(X_train.shape, X_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15402b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42,) (42,)\n",
      "(9,) (9,)\n",
      "(9,) (9,)\n"
     ]
    }
   ],
   "source": [
    "print(indexes_train_dis.shape, indexes_train_con.shape)\n",
    "print(indexes_val_dis.shape, indexes_val_con.shape)\n",
    "print(indexes_test_dis.shape, indexes_test_con.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87cb937d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 64, 64, 34)\n",
      "(18, 64, 64, 34)\n",
      "(18, 64, 64, 34)\n",
      "(84,)\n",
      "(18,)\n",
      "(18,)\n"
     ]
    }
   ],
   "source": [
    "# Create outcome variable for each set (training, validation and test)\n",
    "y_train = target[indexes_train] \n",
    "y_val   = target[indexes_val]\n",
    "y_test  = target[indexes_test]\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f600a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our vectorized labels\n",
    "y_train = np.asarray(y_train).astype('int32')\n",
    "y_test = np.asarray(y_test).astype('int32')\n",
    "y_val = np.asarray(y_val).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6362692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]], shape=(18, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.one_hot(y_train, 2)\n",
    "y_test = tf.one_hot(y_test, 2)\n",
    "y_val = tf.one_hot(y_val, 2)\n",
    "print(y_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "834f2152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 139264)\n",
      "(18, 139264)\n",
      "(18, 139264)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.reshape(len(X_train), -1)\n",
    "print(x_train.shape)\n",
    "x_test = X_test.reshape(len(X_test), -1)\n",
    "print(x_test.shape)\n",
    "x_val = X_val.reshape(len(X_val), -1)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf861ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(84, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4fc1b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train1 = sc.fit_transform(x_train)\n",
    "x_test1 = sc.transform(x_test)\n",
    "x_val1 = sc.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aa21d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 79)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(0.99)\n",
    "x_train1 = pca.fit_transform(x_train1)\n",
    "x_test1 = pca.transform(x_test1)\n",
    "x_val1 = pca.transform(x_val1)\n",
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34876d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                1280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,066\n",
      "Trainable params: 4,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 32ms/step - loss: 0.6918 - accuracy: 0.4762 - val_loss: 0.6889 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6670 - accuracy: 0.6786 - val_loss: 0.6772 - val_accuracy: 0.6111\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6332 - accuracy: 0.7381 - val_loss: 0.6532 - val_accuracy: 0.7222\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5729 - accuracy: 0.8214 - val_loss: 0.6114 - val_accuracy: 0.7778\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4832 - accuracy: 0.8929 - val_loss: 0.5380 - val_accuracy: 0.8889\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3594 - accuracy: 0.9405 - val_loss: 0.4310 - val_accuracy: 0.9444\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2300 - accuracy: 0.9762 - val_loss: 0.3146 - val_accuracy: 0.8889\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1262 - accuracy: 0.9881 - val_loss: 0.2288 - val_accuracy: 0.8889\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0612 - accuracy: 0.9881 - val_loss: 0.1980 - val_accuracy: 0.8889\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.8889\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.8889\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.8889\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.8889\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.8889\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.8889\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.8889\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7.8230e-04 - accuracy: 1.0000 - val_loss: 0.1897 - val_accuracy: 0.8889\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.5891e-04 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.8889\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6499e-04 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.8889\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5.1205e-04 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 0.8889\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.3951e-04 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.8889\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.9850e-04 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.8889\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.7344e-04 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.8889\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.3848e-04 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.8889\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.1658e-04 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.8889\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9299e-04 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.8889\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.7516e-04 - accuracy: 1.0000 - val_loss: 0.1922 - val_accuracy: 0.8889\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5573e-04 - accuracy: 1.0000 - val_loss: 0.1928 - val_accuracy: 0.8889\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.4134e-04 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 0.8889\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.2691e-04 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.8889\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1283e-04 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.8889\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.0187e-04 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.8889\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.8996e-04 - accuracy: 1.0000 - val_loss: 0.1949 - val_accuracy: 0.8889\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.8019e-04 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.8889\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6999e-04 - accuracy: 1.0000 - val_loss: 0.1959 - val_accuracy: 0.8889\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.6152e-04 - accuracy: 1.0000 - val_loss: 0.1962 - val_accuracy: 0.8889\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.5445e-04 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 0.8889\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.4536e-04 - accuracy: 1.0000 - val_loss: 0.1976 - val_accuracy: 0.8889\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3866e-04 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.8889\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3136e-04 - accuracy: 1.0000 - val_loss: 0.1985 - val_accuracy: 0.8889\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2711e-04 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.8889\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1985e-04 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.8889\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.1489e-04 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.8889\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.0995e-04 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.8889\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0550e-04 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.8889\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0183e-04 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.8889\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.7552e-05 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.8889\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.4242e-05 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.8889\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.0420e-05 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 0.8889\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.7412e-05 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.8889\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.3992e-05 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.1089e-05 - accuracy: 1.0000 - val_loss: 0.2042 - val_accuracy: 0.8889\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.8296e-05 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.8889\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.5749e-05 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.8889\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.3030e-05 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.8889\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.0542e-05 - accuracy: 1.0000 - val_loss: 0.2060 - val_accuracy: 0.8889\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.8294e-05 - accuracy: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.8889\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 6.6059e-05 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.8889\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.3931e-05 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.8889\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.2071e-05 - accuracy: 1.0000 - val_loss: 0.2077 - val_accuracy: 0.8889\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0271e-05 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.8889\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.8540e-05 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.8889\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.6609e-05 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.8889\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.4982e-05 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 0.8889\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.3475e-05 - accuracy: 1.0000 - val_loss: 0.2099 - val_accuracy: 0.8889\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.1845e-05 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.8889\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.0526e-05 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.8889\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.9002e-05 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.8889\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.7635e-05 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.8889\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.6313e-05 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.8889\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.5173e-05 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.8889\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.3722e-05 - accuracy: 1.0000 - val_loss: 0.2127 - val_accuracy: 0.8889\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4.2552e-05 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.8889\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.1448e-05 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 0.8889\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.0309e-05 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 0.8889\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.9024e-05 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 0.8889\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.8162e-05 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.8889\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.7067e-05 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.8889\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.6159e-05 - accuracy: 1.0000 - val_loss: 0.2160 - val_accuracy: 0.8889\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 3.5202e-05 - accuracy: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.8889\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.4362e-05 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.8889\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.3522e-05 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.8889\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.2772e-05 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.8889\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1865e-05 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.8889\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3.1197e-05 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.8889\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3.0435e-05 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.8889\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9676e-05 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.8889\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.9055e-05 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.8889\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.8346e-05 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 0.8889\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.7764e-05 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 0.8889\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.7112e-05 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.8889\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.6540e-05 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 0.8889\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5942e-05 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.8889\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.5380e-05 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.8889\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4859e-05 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.8889\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.4337e-05 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.8889\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.3823e-05 - accuracy: 1.0000 - val_loss: 0.2224 - val_accuracy: 0.8889\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2.3309e-05 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.8889\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2850e-05 - accuracy: 1.0000 - val_loss: 0.2230 - val_accuracy: 0.8889\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.2372e-05 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.8889\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.1907e-05 - accuracy: 1.0000 - val_loss: 0.2237 - val_accuracy: 0.8889\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.1477e-05 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 0.8889\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1036e-05 - accuracy: 1.0000 - val_loss: 0.2242 - val_accuracy: 0.8889\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2.0610e-05 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 0.8889\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2.0265e-05 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.8889\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 1.9822e-05 - accuracy: 1.0000 - val_loss: 0.2251 - val_accuracy: 0.8889\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.9465e-05 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 0.8889\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.9078e-05 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8699e-05 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.8889\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.8346e-05 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.8889\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.7985e-05 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.8889\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7651e-05 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.8889\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.7343e-05 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.8889\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.7044e-05 - accuracy: 1.0000 - val_loss: 0.2274 - val_accuracy: 0.8889\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6731e-05 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.8889\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6419e-05 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.8889\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.6105e-05 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.8889\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5834e-05 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.8889\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5556e-05 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 0.8889\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5271e-05 - accuracy: 1.0000 - val_loss: 0.2292 - val_accuracy: 0.8889\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.5017e-05 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.8889\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4754e-05 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.8889\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4504e-05 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.8889\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4260e-05 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.8889\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.4007e-05 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.8889\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3795e-05 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.8889\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.3556e-05 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.8889\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3285e-05 - accuracy: 1.0000 - val_loss: 0.2316 - val_accuracy: 0.8889\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.3087e-05 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.8889\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2873e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.8889\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2657e-05 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 0.8889\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.2480e-05 - accuracy: 1.0000 - val_loss: 0.2326 - val_accuracy: 0.8889\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.2251e-05 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 0.8889\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 1.2065e-05 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.8889\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1872e-05 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.8889\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1678e-05 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.8889\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1476e-05 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.8889\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.1294e-05 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.8889\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.1120e-05 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 0.8889\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0925e-05 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.8889\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0764e-05 - accuracy: 1.0000 - val_loss: 0.2351 - val_accuracy: 0.8889\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0591e-05 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.8889\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1.0426e-05 - accuracy: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.8889\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0268e-05 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.8889\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 1.0124e-05 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.8889\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.9617e-06 - accuracy: 1.0000 - val_loss: 0.2364 - val_accuracy: 0.8889\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.8320e-06 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.8889\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.6799e-06 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.8889\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.5394e-06 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.8889\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.4011e-06 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.8889\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.2831e-06 - accuracy: 1.0000 - val_loss: 0.2378 - val_accuracy: 0.8889\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 9.1318e-06 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 0.8889\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 9.0019e-06 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.8889\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8.8821e-06 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 0.8889\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 8.7494e-06 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.8889\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.6242e-06 - accuracy: 1.0000 - val_loss: 0.2389 - val_accuracy: 0.8889\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.5116e-06 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.8889\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.3888e-06 - accuracy: 1.0000 - val_loss: 0.2394 - val_accuracy: 0.8889\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.2806e-06 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 0.8889\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.1568e-06 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.8889\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 8.0566e-06 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 0.8889\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.9396e-06 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.8889\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.8321e-06 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.8889\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.7266e-06 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.8889\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 7.6253e-06 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.8889\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.5193e-06 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.8889\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 7.4119e-06 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.8889\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.3235e-06 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.8889\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.2157e-06 - accuracy: 1.0000 - val_loss: 0.2420 - val_accuracy: 0.8889\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7.1269e-06 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.8889\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 7.0381e-06 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.8889\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.9376e-06 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.8889\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6.8538e-06 - accuracy: 1.0000 - val_loss: 0.2429 - val_accuracy: 0.8889\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.7645e-06 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.8889\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.6725e-06 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.8889\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.6000e-06 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.8889\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.5089e-06 - accuracy: 1.0000 - val_loss: 0.2438 - val_accuracy: 0.8889\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.4292e-06 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.8889\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 6.3465e-06 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.8889\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.2686e-06 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.8889\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.1936e-06 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.8889\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.1110e-06 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.8889\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 6.0367e-06 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.8889\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.9573e-06 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.8889\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.8941e-06 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 0.8889\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.8164e-06 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.8889\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.7484e-06 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.8889\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6709e-06 - accuracy: 1.0000 - val_loss: 0.2460 - val_accuracy: 0.8889\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.6094e-06 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.8889\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.5425e-06 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.8889\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5.4732e-06 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.8889\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.4088e-06 - accuracy: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.8889\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.3467e-06 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 0.8889\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2860e-06 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.8889\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.2176e-06 - accuracy: 1.0000 - val_loss: 0.2474 - val_accuracy: 0.8889\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.1626e-06 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.8889\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 5.1054e-06 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.8889\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 5.0452e-06 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.8889\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 4.9905e-06 - accuracy: 1.0000 - val_loss: 0.2481 - val_accuracy: 0.8889\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 4.9276e-06 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x226a52c3c40>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANN code\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(16, kernel_initializer= \"uniform\", input_shape= x_train1[0].shape, activation='relu'),\n",
    "    keras.layers.Dense(32, kernel_initializer= \"uniform\", activation='relu'),\n",
    "    keras.layers.Dense(64, kernel_initializer= \"uniform\", activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.fit(x_train1, y_train, validation_data=(x_val1, y_val) ,epochs=200, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baf7ee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5336 - accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.533585786819458, 0.8888888955116272]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e72dc3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.67994369e-07, 9.99999523e-01],\n",
       "       [9.99999881e-01, 7.32318028e-08],\n",
       "       [9.99999881e-01, 1.42007835e-07],\n",
       "       [1.00000000e+00, 1.22791724e-13],\n",
       "       [1.00000000e+00, 5.74306047e-10],\n",
       "       [1.00000000e+00, 4.82301959e-12],\n",
       "       [1.00000000e+00, 7.78770914e-09],\n",
       "       [1.00000000e+00, 1.74255228e-12],\n",
       "       [9.99879479e-01, 1.20489945e-04],\n",
       "       [9.87824798e-01, 1.21752284e-02],\n",
       "       [4.52145377e-10, 1.00000000e+00],\n",
       "       [1.86526246e-11, 1.00000000e+00],\n",
       "       [6.81017298e-07, 9.99999285e-01],\n",
       "       [3.34795386e-11, 1.00000000e+00],\n",
       "       [1.49252033e-09, 1.00000000e+00],\n",
       "       [6.31297610e-08, 9.99999881e-01],\n",
       "       [4.50067077e-08, 1.00000000e+00],\n",
       "       [5.01873499e-12, 1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze prediction values\n",
    "\n",
    "\n",
    "\n",
    "predicted = model.predict(x_test1)\n",
    "predicted[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c06cdfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89         9\n",
      "           1       0.89      0.89      0.89         9\n",
      "\n",
      "    accuracy                           0.89        18\n",
      "   macro avg       0.89      0.89      0.89        18\n",
      "weighted avg       0.89      0.89      0.89        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import confusion matrix and classification report from scikit-learn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "Y_prediction = model.predict(x_test1)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(predicted,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(target[indexes_test], Y_pred_classes) \n",
    "print(classification_report(target[indexes_test], Y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3821cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_mtx, annot=True, fmt=\"d\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82a2767c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18, 2), dtype=float32, numpy=\n",
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7bd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
